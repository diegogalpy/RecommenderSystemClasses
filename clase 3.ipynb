{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clase 3.ipynb","provenance":[],"authorship_tag":"ABX9TyOSdWL6cjtvlKl79bT/0Quo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pAX8r3FnBywU","colab_type":"text"},"source":["# Sistemas de Recomendacion avanzados\n","\n","Diego Galeano, Ph.D.\n","\n","Material basado en: https://developers.google.com/machine-learning/recommendation/labs/movie-rec-programming-exercise"]},{"cell_type":"code","metadata":{"id":"BhO4nPdIB3bc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":154},"executionInfo":{"status":"ok","timestamp":1600122467989,"user_tz":180,"elapsed":2897,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"ecf67d5d-3201-4abc-d2f6-f9a79d893348"},"source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd \n","import numpy as np\n","import copy\n","import random\n","import scipy.io\n","from scipy.optimize import minimize\n","from scipy.optimize import differential_evolution\n","\n","# If you want to have direct access to the datasets and codes you can clone the following github repository    \n","! git clone https://github.com/saminehbagheri/Recommender-System.git\n","%cd Recommender-System  "],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["Cloning into 'Recommender-System'...\n","remote: Enumerating objects: 66, done.\u001b[K\n","remote: Total 66 (delta 0), reused 0 (delta 0), pack-reused 66\u001b[K\n","Unpacking objects: 100% (66/66), done.\n","/content/Recommender-System\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4DFXKIjvCRG_","colab_type":"text"},"source":["### Leemos el Movielens dataset"]},{"cell_type":"code","metadata":{"id":"5hWvrmKZCHLE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1599394012396,"user_tz":180,"elapsed":757,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"fcd72c71-44c3-4889-f4a4-0be258ad3e13"},"source":["mat = scipy.io.loadmat('ex8_movies.mat')\n","movie_names = pd.read_csv('movie_ids.txt',delimiter=';',header=None)[1]\n","Y=mat['Y']\n","R=mat['R']\n","num_user=Y.shape[1]\n","num_movie=Y.shape[0]\n","density= 100*np.sum(np.where(Y > 0,1,0))/(num_user*num_movie)\n","print(\"numero de usuarios:\"+str(num_user))\n","print(\"numero de peliculas:\"+str(num_movie))\n","print(\"densidad del rating matrix: \"+str(density) + '%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["numero de usuarios:943\n","numero de peliculas:1682\n","densidad del rating matrix: 6.304669364224532%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GOPOm-XsCyt7","colab_type":"text"},"source":["## Matrix factorizacion: collaborative filtering\n","\n","Recordando el sistema de recomendación basado en contenido, la idea era describir cada item y cada usuario con un vector de características importantes. En nuestro ejemplo de la clase anterior, el vector de características que usamos tenía solo tres elementos, pero somos conscientes de que hay criterios mucho más importantes que esos tres para capturar nuestro interés por una película y, a veces, estas características pueden ser más complicadas que simplemente el género de la película.\n","\n"," Matrix Factorization supone que podemos describir una película y un usuario en forma de un vector de características. La idea principal de la factorización matricial es encontrar el vector de característica de usuario adecuado $ \\vec {x}_i $ y el vector de característica de elemento $ \\vec{\\theta}_j $ para todos los usuarios $ i = 1 \\cdots n_u $ y películas $ j = 1 \\cdots n_m $ que sus productos punto dan una buena estimación de la calificación que el $ i $ -ésimo usuario daría a la $ j $ -ésima película $ y_ {ij} $.\n","\n"," **Porque este metodo se llama decomposicion de matrices?** Porque el rating que un usuario da a una pelicula se modela como el producto escalar entre el vector de caracteristicas del usuario y el vector de caracteristicas de la pelicula, es decir: $\\vec{x}_i\\cdot\\vec{\\theta}_j=y_{ij}$. Supongamos que apilamos todos los vectores de características del usuario en la matriz de características del usuario $\\mathbf{X}=\\begin{bmatrix}-\\vec{x}_1^T-\\\\ -\\vec{x}_2^T- \\\\ \\vdots \\\\-\\vec{x}_{n_u}^T- \\end{bmatrix}_{n_u \\times n_f}$  y todos los vectores de características de la película juntos en la matriz de características de la película $\\mathbf{\\Theta}=\\begin{bmatrix}-\\vec{\\theta}_1^T-\\\\ -\\vec{\\theta}_2^T- \\\\ \\vdots \\\\-\\vec{\\theta}_{n_m}^T- \\end{bmatrix}_{n_m \\times n_f}$. Entonces, la matriz de calificación se puede determinar de la siguiente manera:\n","\n"," \n","\\begin{equation}\\mathbf{\\Theta} \\cdot \\mathbf{X}^T=\\mathbf{R}\\end{equation}\n","\\begin{equation}\\begin{bmatrix}- \\vec{\\theta}_1^T-\\\\ - \\vec{\\theta}_2^T- \\\\ \\vdots \\\\- \\vec{\\theta}_{n_m}^T- \\end{bmatrix} \\cdot \\begin{bmatrix}|&|&\\cdots&|\\\\\n","               \\vec{x_1}&\\vec{x_2}&\\cdots&\\vec{x}_{n_u}\\\\\n","               |&|&\\cdots&|\\end{bmatrix}=\\mathbf{R}\\end{equation}\n","\n","Sería perfecto si tuviéramos las matrices de características adecuadas, pero no las tenemos. Lo que en realidad tenemos es la matriz de calificación $ \\mathbf{Y}$ e intentamos *aprender* las matrices de características de $ \\mathbf{Y}$. El nombre **factorización de matrices** proviene de este punto que este algoritmo tiende a encontrar matrices de características razonablemente óptimas al factorizar la matriz de calificación $ \\mathbf{Y}$.\n","\n","**¿Cómo funciona la factorización de matrices?** Supongamos que iniciamos las matrices de características con valores completamente aleatorios. El producto escalar del vector de características de usuario $ i$ -ésimo y el vector de características de película $ j $ -ésimo dará $ p_{ij} $ que probablemente sea muy diferente a la calificación real dada $ y_{ij} $. La idea es encontrar las matrices de características de manera que el error $ | p_{ij} -y_{ij} | $ sea lo más mínimo posible para todas las calificaciones dadas. En otras palabras, la factorización matricial se convirtió en un problema de optimización de minimizar una función de costo que es la suma de todos los errores $ \\color {green}{\\text{al cuadrado}} $ para todas las celdas con una calificación. La función de costo a minimizar se define de la siguiente manera:\n","\n","\n","\\begin{equation}J(\\mathbf{\\Theta},\\mathbf{X})=\\frac{1}{2} \\sum\\limits_{(i,j):r(i,j)=\\{1\\}} (\\vec{\\theta}_{j} \\vec{x}_{i}-y_{i,j})^2\\end{equation}\n","\n","**¿Cómo resolver un problema de optimización de este tipo?** Podemos pasar la función de costo con un punto de partida aleatorio a un optimizador y esperar hasta que el optimizador encuentre una solución óptima, pero esto llevará un tiempo insoportablemente largo ya que el problema de optimización es dimensional muy alto. ¿Puede adivinar cuál es la dimensión de entrada de este problema de optimización? $ (n_u + n_m) * n_f $, donde $ n_f $ es el número de caracteristicas.\n","\n","Es más lógico calcular los gradientes hacia la solución óptima de manera iterativa mediante un descenso de gradiente o métodos de gradiente conjugado. Es muy sencillo calcular los gradientes ya que nuestra función de costo es una función cuadrática.\n","\n","\n","## The Gradients\n"," \\begin{equation}\\frac{\\partial J}{\\partial x_i^{(k)}}=\\sum\\limits_{j:r(i,j)=1}(\\vec{\\theta}_{j} \\vec{x}_{i}-y_{i,j})\\theta^{(k)}_j,\\end{equation}\n"," \\begin{equation}\\frac{\\partial J}{\\partial \\theta_j^{(k)}}=\\sum\\limits_{i:r(i,j)=1}(\\vec{\\theta}_{j} \\vec{x}_{i}-y_{i,j})x^{(k)}_i,\\end{equation}\n","\n"," \n","donde $x^{(k)}_j$ es el elemento $k$-esimo del $i$-esimo vector de caracteristicas del usuario $\\vec{x}_i$. \n","\n","Los pasos principales del algoritmo de factorización matricial se pueden resumir a continuación:\n","\n","1. Inicialice $ \\mathbf {\\Theta} $ y $ \\mathbf{X} $ con números pequeños aleatorios\n","2. Minimice la función de costo $ J (\\mathbf{\\Theta}, \\mathbf{X}) $\n","3. Utilice las matrices de características optimizadas para predecir"]},{"cell_type":"markdown","metadata":{"id":"ma-LM4BqGlzk","colab_type":"text"},"source":["<a id='MFPy'> </a>\n","# Implementación de factorización matricial\n","\n","## Función de inicialización de parámetros\n","Esta función simplemente obtiene el número de usuarios, el número de elementos y el número de características como entrada y devuelve la matriz de características del usuario iniciada aleatoriamente y la matriz de características del elemento."]},{"cell_type":"code","metadata":{"id":"PuzuDhl_CLbv","colab_type":"code","colab":{}},"source":["def initilizeFeat(nu,ni,nf,seed=42):\n","    '''\n","    Inicializacion de las matrices de caracteristicas.\n","    '''\n","    # semilla de randomizacion\n","    np.random.seed(seed)\n","    # inicializacion aleatoria de matrices de caracteristicas\n","    Theta = np.random.rand(nu,nf)*0.05\n","    X = np.random.rand(ni,nf)*0.05\n","    return X, Theta"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Td4FNUjmHHgq","colab_type":"text"},"source":["## Funciones auxiliares\n","Tenemos dos funciones auxiliares. Una para aplanar las matrices de características en una matriz 1-D, y otra hace lo inverso."]},{"cell_type":"code","metadata":{"id":"w_XlfPSBFbyC","colab_type":"code","colab":{}},"source":["def flatterRev(x,nu,ni,nf):\n","    '''\n","    Convierte un vector 1-D a las matrices de caracteristicas X y Theta.\n","      x: vector 1-D.\n","      nu: numero de usuarios.\n","      ni: numero de items.\n","      nf: numero de caracteristicas.    \n","    ''' \n","    X=x[0:ni*nf].reshape((ni,nf),order='F')\n","    Theta=x[ni*nf:].reshape((nu,nf),order='F')\n","    return X,Theta\n","\n","def flatter(X, Theta):\n","    '''\n","    Convierte las matrices de caracteristicas a un vector 1-D.\n","      X: matriz de caracteristicas de usuarios.\n","      Theta: matriz de caracteristicas de peliculas.\n","    ''' \n","    x=np.concatenate([X.reshape(X.shape[0]*X.shape[1],order='F'),Theta.reshape(Theta.shape[0]*Theta.shape[1],order='F')])\n","    return(x)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c-IB6DHIHvkc","colab_type":"text"},"source":["# Función de costo\n","La función de costo es simplemente la implementación de la fórmula de la función de costo que hemos discutido anteriormente en una forma vectorizada para evitar bucles for anidados para las sumas. La única diferencia es un término adicional vinculado con el parámetro $ \\lambda $, el parámetro de regularización."]},{"cell_type":"code","metadata":{"id":"zB7zbLI8HrWE","colab_type":"code","colab":{}},"source":["def costFunc(X,Theta,R,M,la=0):\n","    '''\n","    Funcion auxiliar de la funcion de costo.\n","\n","    '''\n","    R=np.ma.array(R, mask=M)\n","    e=0.5*np.sum(np.power((np.dot(Theta,X.T)-R),2))+la*0.5*np.sum(np.power(Theta, 2))+la*0.5*np.sum(np.power(X, 2))\n","    return(e/np.sum(M==False))\n","\n","\n","def CF(x,R,M,nu,ni,nf,la=0):\n","    '''\n","    Funcion de costo con termino de regularizacion.\n","      x: 1-D vector que contiene X y Theta.\n","      R: matriz de ratings.\n","      M: matriz de enmascaramiento para solo optimizar en los ratings observados.\n","      nu: numero de usuarios.\n","      ni: numero de items.\n","      nf: numero de caracteristicas. \n","      la: lambda, termino de regularizacion L2.   \n","    ''' \n","    X, Theta=flatterRev(x,nu,ni,nf)\n","    error=costFunc(X,Theta,R,M,la=la)\n","    return error"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zF9dpXrWIaSN","colab_type":"text"},"source":["# Gradiente"]},{"cell_type":"code","metadata":{"id":"9hU7cu4gH-6V","colab_type":"code","colab":{}},"source":["def gradFunc(x,R,M,nu,ni,nf,la=0 ):\n","    '''\n","    Retorna los gradientes para el optimizador.\n","\n","    '''\n","    X, Theta=flatterRev(x,nu,ni,nf)\n","    R=np.ma.array(R, mask=M)\n","    e=np.dot(Theta,X.T)-R\n","    TG=np.dot(e,X)+la*Theta\n","    XG=np.dot(e.T,Theta)+la*X\n","    grads=np.concatenate([XG.reshape(XG.shape[0]*XG.shape[1],order='F'),TG.reshape(TG.shape[0]*TG.shape[1],order='F')])\n","    return grads/np.sum(M==False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dV821yCUIl7I","colab_type":"text"},"source":["## Función de entrenamiento\n","\n","La función de entrenamiento en realidad es solo aplicar un algoritmo de optimización en la función de costo. Usamos un optimizador de gradiente conjugado incorporado de la biblioteca scipy. Es posible que desee probar diferentes métodos."]},{"cell_type":"code","metadata":{"id":"NchXDyYbIgbx","colab_type":"code","colab":{}},"source":["def trainMF(R,M,nf,la=0,seed=42):\n","    nu=R.shape[0]\n","    ni=R.shape[1]\n","    R=np.ma.array(R, mask=M)\n","    X, Theta=initilizeFeat(nu,ni,nf,seed=seed)\n","    x=flatter(X, Theta)  \n","    \n","    res = minimize(CF, x, args=(R,M,nu,ni,nf,la), method='CG',jac=gradFunc,options={ 'disp': True,'gtol':1e-5})\n","    MSE=CF(res.x,R,M,nu,ni,nf,la)\n","    return(MSE, res,nu,ni,nf)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P1GhdaWUI9BI","colab_type":"text"},"source":["# Funcion de prediccion"]},{"cell_type":"code","metadata":{"id":"CzDWWw_VI6C0","colab_type":"code","colab":{}},"source":["def Predict(res,nu,ni,nf,la=0):\n","    X, Theta=flatterRev(res.x,nu,ni,nf)\n","    predict=np.dot(Theta,X.T)\n","    return(predict)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_g-bqmFuKRji","colab_type":"text"},"source":["# Construyendo el modelo del sistema de recomendación"]},{"cell_type":"code","metadata":{"id":"-05Qx98fKHG9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1599392900147,"user_tz":180,"elapsed":49951,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"d057ce35-d7bf-4f7f-ba81-3caa610d2fc1"},"source":["runEXAMPLE=True\n","def buildRSModel(R,M,mu=None, nf=10,la=0,seed=42, movie_names=None):\n","    trainR=copy.copy(R)\n","    trainM=copy.copy(M)\n","\n","    trainR=np.ma.array(trainR, mask=trainM)\n","    if mu is None:\n","        mu=np.average(trainR,axis=1)\n","    trainR=trainR-mu[:,None]\n","    trainingError, res,nu,ni,nf=trainMF(trainR,M,nf=nf,la=la,seed=seed)\n","    model={'trainingError': trainingError, 'res':res,'nu':nu,'ni':ni,'nf':nf, 'la':la, 'movie_names':movie_names, 'mu':mu,\n","          'R':R,'M':M}\n","    return model\n","\n","#Ejemplo\n","if runEXAMPLE:\n","    R=mat['Y']\n","    M=mat['R']\n","    trainR=copy.copy(R)\n","    trainM= (M==0)\n","    mymodel=buildRSModel(R=trainR,M=trainM,mu=None, nf=100,la=0,seed=42, movie_names=movie_names)\n","    #print(mymodel)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.158532\n","         Iterations: 16\n","         Function evaluations: 335\n","         Gradient evaluations: 324\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"PSwmSKByKX0S","colab_type":"text"},"source":["# Predicción para el usuario X"]},{"cell_type":"code","metadata":{"id":"RQ28rZNvKUbg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"executionInfo":{"status":"ok","timestamp":1599393014074,"user_tz":180,"elapsed":795,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"c99835ae-b2aa-4e2a-b0ba-e497a665f880"},"source":["runEXAMPLE=True\n","def predictForUserX(user_Id,model,movie_Id=None):\n","    trainingError=model['trainingError']\n","    res=model['res']\n","    nu=model['nu']\n","    ni=model['ni']\n","    nf=model['nf']\n","    la=model['la']\n","    movie_names=model['movie_names']\n","    mu=model['mu']\n","    R=model['R']\n","    M=model['M']\n","    mypredict=Predict(res,nu,ni,nf,la=0)\n","    mydata=pd.DataFrame()\n","    Pred=mypredict[:,user_Id]+mu[user_Id]\n","    mydata['names']=movie_names\n","    mydata['predictedRating']=Pred\n","    mydata['originalrating']=R[:,user_Id]\n","    mydata=mydata.sort_values(by=['predictedRating'], ascending=False)\n","    output=mydata[mydata['originalrating'] == 0]\n","    return(output)\n","\n","#Example\n","if runEXAMPLE:\n","    user_id = 125\n","    print(predictForUserX(user_id,mymodel,movie_Id=None).head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["                              names  predictedRating  originalrating\n","471               Dragonheart(1996)         4.268084               0\n","679        Kull the Conqueror(1997)         4.233533               0\n","320                    Mother(1996)         4.195186               0\n","627                  Sleepers(1996)         4.182644               0\n","221  Star Trek: First Contact(1996)         4.162360               0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6zFwbJbDKkQ-","colab_type":"text"},"source":["# Ingrese su propia calificación\n","\n","Puede usar esta función para ingresar su propia calificación y ver lo que sugiere el sistema. Si no configura el parámetro model, se utilizarán los valores predeterminados de nf = 100, la = 0.1."]},{"cell_type":"code","metadata":{"id":"05GIEzohKf1N","colab_type":"code","colab":{}},"source":["def weRecommend(myratings,modelparam=None):\n","    movie_names = pd.read_csv('movie_ids.txt',delimiter=';',header=None)[1]\n","    mat = scipy.io.loadmat('ex8_movies.mat')\n","    print(\"Reading the data\")\n","    R=mat['Y']\n","    M=mat['R']\n","    trainR=copy.copy(R)\n","    trainM= (M==0)\n","    num_user=R.shape[1]\n","    num_movie=R.shape[0]\n","    \n","    \n","    myratings=myratings.sort_values(by=['names'], ascending=False)\n","    movies=copy.copy(movie_names)\n","    movies=movies.sort_values( ascending=False)\n","    indices=movies[movies.isin( myratings['names'])].index\n","    newuserratingR=np.zeros(num_movie)\n","    newuserratingM=np.zeros(num_movie)\n","    newuserratingR[indices]=myratings['rating']\n","    newuserratingM[indices]=1\n","    \n","    newuserratingM= (newuserratingM==0)\n","    trainR=np.concatenate((newuserratingR[:,None],trainR),axis=1)\n","    trainM=np.concatenate((newuserratingM[:,None],trainM),axis=1)\n","    \n","    print(\"Training the Recommender System...\")\n","    if modelparam is None:\n","        mymodel=buildRSModel(R=trainR,M=trainM,mu=None, nf=100,la=0.1, movie_names=movie_names)\n","    else:\n","        nf=modelparam['nf']\n","        la=modelparam['la'] \n","        mymodel=buildRSModel(R=trainR,M=trainM,mu=None, nf=nf,la=la, movie_names=movie_names)\n","    print(\"Training is successfully finished\")   \n","    bests=predictForUserX(0,mymodel,movie_Id=None).head(15)\n","    worsts=predictForUserX(0,mymodel,movie_Id=None).tail(15)\n","    print(\"Predicting you're ratings:\")\n","    bests=bests.iloc[:, :-1]\n","    worsts=worsts.iloc[:, :-1]\n","    output={'bests':bests,'worsts':worsts}\n","    return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"etuBmXuPKp-o","colab_type":"code","colab":{}},"source":[" movie_names = pd.read_csv('movie_ids.txt',delimiter=';',header=None)[1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfK7WRg6QfxC","colab_type":"code","colab":{}},"source":["df = pd.DataFrame()\n","df['rating'] = [5,4,5,5,5]\n","df['names'] = ['Toy Story(1995)', 'Batman Forever(1995)', 'Ace Ventura: Pet Detective(1994)', 'Lion King  The(1994)', 'Mask  The(1994)' ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e2k_gQK8Qgy1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":714},"executionInfo":{"status":"ok","timestamp":1599393558199,"user_tz":180,"elapsed":40324,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"a0cdc1ef-3d47-41a3-adfd-db5cf3cd856d"},"source":[" weRecommend(df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading the data\n","Training the Recommender System...\n","Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.164909\n","         Iterations: 16\n","         Function evaluations: 274\n","         Gradient evaluations: 263\n","Training is successfully finished\n","Predicting you're ratings:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["{'bests':                                    names  predictedRating\n"," 94                         Aladdin(1992)         4.137037\n"," 587           Beauty and the Beast(1991)         4.103507\n"," 741                         Ransom(1996)         4.080346\n"," 236                  Jerry Maguire(1996)         4.039222\n"," 185            Blues Brothers  The(1980)         4.032696\n"," 392                 Mrs. Doubtfire(1993)         4.028297\n"," 293                      Liar Liar(1997)         4.027884\n"," 158                 Basic Instinct(1992)         4.027414\n"," 767                         Casper(1995)         4.020870\n"," 229  Star Trek IV: The Voyage Home(1986)         4.020013\n"," 635           Escape from New York(1981)         4.018811\n"," 595   Hunchback of Notre Dame  The(1996)         4.017570\n"," 6                   Twelve Monkeys(1995)         4.015794\n"," 68                    Forrest Gump(1994)         4.013471\n"," 95      Terminator 2: Judgment Day(1991)         4.012567,\n"," 'worsts':                              names  predictedRating\n"," 273                  Sabrina(1995)         3.787733\n"," 215  When Harry Met Sally...(1989)         3.784047\n"," 184                   Psycho(1960)         3.782446\n"," 270        Starship Troopers(1997)         3.779023\n"," 746             Benny & Joon(1993)         3.778370\n"," 495     Its a Wonderful Life(1946)         3.776042\n"," 339            Boogie Nights(1997)         3.768823\n"," 244          Devils Own  The(1997)         3.767892\n"," 474            Trainspotting(1996)         3.763347\n"," 214          Field of Dreams(1989)         3.761476\n"," 684       Executive Decision(1996)         3.748189\n"," 172      Princess Bride  The(1987)         3.732079\n"," 143                 Die Hard(1988)         3.730593\n"," 149                 Swingers(1996)         3.724997\n"," 116                Rock  The(1996)         3.685122}"]},"metadata":{"tags":[]},"execution_count":94}]},{"cell_type":"markdown","metadata":{"id":"ylHth-djTGyn","colab_type":"text"},"source":["# Optimizar los parametros del sistema de recomendacion"]},{"cell_type":"markdown","metadata":{"id":"8a5zmTQiJl_H","colab_type":"text"},"source":["## Función de error de prueba\n","\n","Existen diferentes enfoques para evaluar el desempeño de un sistema de recomendación en los datos de prueba. Un método consiste en calcular el error cuadrático medio de los datos de prueba. Otro enfoque es medir algún tipo de precisión de predicción. En la siguiente celda, definimos la precisión como el porcentaje de las calificaciones pronosticadas que tienen un error de 1 o menos."]},{"cell_type":"code","metadata":{"id":"oVsEaQR6Je1t","colab_type":"code","colab":{}},"source":["def testMF(tR,tM,predict):\n","    tR=np.ma.array(tR, mask=tM)\n","    e=np.abs(tR-predict)\n","    testMSE=np.sum(np.power(e,2))/np.sum(tM==False)\n","    return(testMSE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QpEiETbyTQG8","colab_type":"code","colab":{}},"source":["def splitMatrix(R,M,testPer):\n","    trainPer=1-testPer\n","    num_user=R.shape[1]\n","    num_movie=R.shape[0]\n","    overallRating=np.sum(M)\n","    testsize=testPer*overallRating\n","    testsize=testsize.astype(int)\n","\n","\n","    #split tarining and test dataset\n","    random.seed( 9273482 )\n","    ind1, ind2=np.where(M==1)\n","    testSamples=random.sample(range(ind1.shape[0]), testsize)\n","    testInd1=ind1[testSamples]\n","    testInd2=ind2[testSamples]\n","\n","    trainR=copy.copy(R)\n","    trainM=copy.copy(M)\n","    trainR[testInd1,testInd2]=0\n","    trainM[testInd1,testInd2]=0\n","\n","\n","    M= (trainM==0)\n","    trainR=np.ma.array(trainR, mask=M)\n","    mu=np.average(trainR,axis=1)\n","\n","    testR=copy.copy(R)\n","    testM=np.zeros(shape = (testR.shape[0],testR.shape[1]))\n","    testM[testInd1,testInd2]=1\n","    tM=(testM==0)\n","    testR=testR*testM\n","    testR=np.ma.array(testR, mask=tM)\n","    return trainR, M, testR, tM, mu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A65ybIXTTWEX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":493},"executionInfo":{"status":"ok","timestamp":1599395120021,"user_tz":180,"elapsed":30471,"user":{"displayName":"Diego Galeano","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhQWXSahinhC5AIsR14l3qpJg37OGXBVT0uRAsarw=s64","userId":"05605395687006727326"}},"outputId":"a2a1b526-8598-486d-ef0c-48d00ccc5317"},"source":["DORUN=True\n","\n","trainR, M, testR, tM, mu=splitMatrix(Y,R,0.1)\n","NF=[1,5,10,20]\n","myseed=5623\n","if DORUN:\n","    trainR=trainR-mu[:,None]\n","    testR=testR-mu[:,None]\n","\n","    for nf in NF:        \n","        trainingError, res,nu,ni,nf=trainMF(trainR,M,nf=nf,la=0.1,seed=myseed)\n","        mypredict=Predict(res,nu,ni,nf,la=0)\n","        zeropredict=np.zeros(shape = (mypredict.shape[0],mypredict.shape[1]))        \n","        testError=testMF(testR,tM,mypredict)\n","        \n","        print('[nf='+str(nf)+']'+'Training Error:'+str(trainingError))\n","        print('[nf='+str(nf)+']'+'Test Error:'+str(testError))\n","     "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.467095\n","         Iterations: 4\n","         Function evaluations: 74\n","         Gradient evaluations: 63\n","[nf=1]Training Error:0.46709498777841846\n","[nf=1]Test Error:0.995016231120181\n","Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.466449\n","         Iterations: 3\n","         Function evaluations: 103\n","         Gradient evaluations: 91\n","[nf=5]Training Error:0.46644884839687906\n","[nf=5]Test Error:0.9962897332608236\n","Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.463523\n","         Iterations: 2\n","         Function evaluations: 59\n","         Gradient evaluations: 48\n","[nf=10]Training Error:0.4635231472060253\n","[nf=10]Test Error:0.9924336179545064\n","Warning: Desired error not necessarily achieved due to precision loss.\n","         Current function value: 0.466339\n","         Iterations: 3\n","         Function evaluations: 92\n","         Gradient evaluations: 80\n","[nf=20]Training Error:0.4663389769881152\n","[nf=20]Test Error:0.9980363109345022\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XJLFY5-8T5g3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}